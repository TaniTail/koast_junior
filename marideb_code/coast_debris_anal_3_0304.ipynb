{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024 누적선박밀집도와 해양쓰레기, 해류 데이터를 함께 보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트를 찾았습니다: C:/Windows/Fonts/malgun.ttf\n",
      "한글 폰트를 찾았습니다: C:/Windows/Fonts/malgun.ttf\n",
      "==================================================\n",
      "선박밀집도, 해류, 해양쓰레기 통합 분석을 시작합니다.\n",
      "==================================================\n",
      "\n",
      "1. 해양쓰레기 데이터 로드\n",
      "- 해양쓰레기 데이터 로드: 개수 범위 45~11420\n",
      "- 총 60개의 정점 데이터가 로드되었습니다.\n",
      "\n",
      "2. 정점별 가장 가까운 그리드 정보 로드\n",
      "- 해양쓰레기 정점 그리드 60개를 로드했습니다.\n",
      "\n",
      "3. 해류 데이터 로드\n",
      "- 해류 데이터 로드: 총 4532544개 데이터 포인트\n",
      "- 데이터 기간: 2024-01-01 00:00:00 ~ 2024-12-31 23:00:00\n",
      "- 해류 방향 범위: 0° ~ 360°\n",
      "- 해류 속도 범위: 0.0 ~ 241.0 단위\n",
      "- 위경도 범위: 경도 (125.00015, 129.86137), 위도 (33.04701, 37.69467)\n",
      "\n",
      "4. 선박밀집도 데이터 누적 계산\n",
      "- 총 715개 시간대의 선박밀집도 데이터를 분석합니다.\n",
      "- 총 3765개의 그리드 위치 정보를 추출했습니다.\n",
      "- 선박밀집도 데이터 누적 계산 중...\n",
      "  처리 중: 2023-01-01 00:00 (1/715)\n",
      "  처리 중: 2023-01-02 00:00 (25/715)\n",
      "  처리 중: 2023-01-03 00:00 (49/715)\n",
      "  처리 중: 2023-01-04 00:00 (73/715)\n",
      "  처리 중: 2023-01-05 00:00 (97/715)\n",
      "  처리 중: 2023-01-06 00:00 (121/715)\n",
      "  처리 중: 2023-01-07 00:00 (145/715)\n",
      "  처리 중: 2023-01-08 00:00 (169/715)\n",
      "  처리 중: 2023-01-09 00:00 (193/715)\n",
      "  처리 중: 2023-01-10 00:00 (217/715)\n",
      "  처리 중: 2023-01-11 00:00 (241/715)\n",
      "  처리 중: 2023-01-12 00:00 (265/715)\n",
      "  처리 중: 2023-01-13 00:00 (289/715)\n",
      "  처리 중: 2023-01-14 03:00 (313/715)\n",
      "  처리 중: 2023-01-15 03:00 (337/715)\n",
      "  처리 중: 2023-01-16 03:00 (361/715)\n",
      "  처리 중: 2023-01-17 03:00 (385/715)\n",
      "  처리 중: 2023-01-18 03:00 (409/715)\n",
      "  처리 중: 2023-01-19 03:00 (433/715)\n",
      "  처리 중: 2023-01-20 03:00 (457/715)\n",
      "  처리 중: 2023-01-21 03:00 (481/715)\n",
      "  처리 중: 2023-01-22 03:00 (505/715)\n",
      "  처리 중: 2023-01-23 03:00 (529/715)\n",
      "  처리 중: 2023-01-24 03:00 (553/715)\n",
      "  처리 중: 2023-01-25 03:00 (577/715)\n",
      "  처리 중: 2023-01-26 05:00 (601/715)\n",
      "  처리 중: 2023-01-27 05:00 (625/715)\n",
      "  처리 중: 2023-01-28 05:00 (649/715)\n",
      "  처리 중: 2023-01-29 05:00 (673/715)\n",
      "  처리 중: 2023-01-30 05:00 (697/715)\n",
      "- 최대 누적 선박밀집도: 71497.76\n",
      "\n",
      "5. 정점별 선박밀집도, 해류, 쓰레기 데이터 통합\n",
      "- 총 54개 정점에 대해 통합 데이터를 생성했습니다.\n",
      "\n",
      "6. 상관관계 분석\n",
      "- 누적_선박밀집도와(과) 쓰레기 개수의 상관계수: 0.100\n",
      "- 평균_선박밀집도와(과) 쓰레기 개수의 상관계수: 0.100\n",
      "- 누적_교통량와(과) 쓰레기 개수의 상관계수: 0.069\n",
      "- 평균_교통량와(과) 쓰레기 개수의 상관계수: 0.071\n",
      "- 해류_평균속도와(과) 쓰레기 개수의 상관계수: -0.014\n",
      "- 해류_최대속도와(과) 쓰레기 개수의 상관계수: 0.073\n",
      "\n",
      "7. 통합 시각화\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:661: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  summary_text += f\"{var}: {model.params[i]:.4f} (p={model.pvalues[i]:.4f})\\n\"\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:661: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  summary_text += f\"{var}: {model.params[i]:.4f} (p={model.pvalues[i]:.4f})\\n\"\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:670: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  summary_text += f\"{var}: {importance[i]:.1f}%\\n\"\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 47049 (\\N{HANGUL SYLLABLE RYANG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 54924 (\\N{HANGUL SYLLABLE HOE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 44480 (\\N{HANGUL SYLLABLE GWI}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 49437 (\\N{HANGUL SYLLABLE SEOG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 44208 (\\N{HANGUL SYLLABLE GYEOL}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 44284 (\\N{HANGUL SYLLABLE GWA}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 44228 (\\N{HANGUL SYLLABLE GYE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 54637 (\\N{HANGUL SYLLABLE HANG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 45572 (\\N{HANGUL SYLLABLE NU}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 49440 (\\N{HANGUL SYLLABLE SEON}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 48149 (\\N{HANGUL SYLLABLE BAG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 48128 (\\N{HANGUL SYLLABLE MIL}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 51665 (\\N{HANGUL SYLLABLE JIB}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 54644 (\\N{HANGUL SYLLABLE HAE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 47448 (\\N{HANGUL SYLLABLE RYU}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 54217 (\\N{HANGUL SYLLABLE PYEONG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 44512 (\\N{HANGUL SYLLABLE GYUN}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 49549 (\\N{HANGUL SYLLABLE SOG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 51473 (\\N{HANGUL SYLLABLE JUNG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:694: UserWarning: Glyph 50836 (\\N{HANGUL SYLLABLE YO}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 47049 (\\N{HANGUL SYLLABLE RYANG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 54924 (\\N{HANGUL SYLLABLE HOE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 44480 (\\N{HANGUL SYLLABLE GWI}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 49437 (\\N{HANGUL SYLLABLE SEOG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 44208 (\\N{HANGUL SYLLABLE GYEOL}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 44284 (\\N{HANGUL SYLLABLE GWA}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 44228 (\\N{HANGUL SYLLABLE GYE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 54637 (\\N{HANGUL SYLLABLE HANG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 45572 (\\N{HANGUL SYLLABLE NU}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 49440 (\\N{HANGUL SYLLABLE SEON}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 48149 (\\N{HANGUL SYLLABLE BAG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 48128 (\\N{HANGUL SYLLABLE MIL}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 51665 (\\N{HANGUL SYLLABLE JIB}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 54644 (\\N{HANGUL SYLLABLE HAE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 47448 (\\N{HANGUL SYLLABLE RYU}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 54217 (\\N{HANGUL SYLLABLE PYEONG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 44512 (\\N{HANGUL SYLLABLE GYUN}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 49549 (\\N{HANGUL SYLLABLE SOG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 51473 (\\N{HANGUL SYLLABLE JUNG}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\TAN\\AppData\\Local\\Temp\\ipykernel_18092\\1350961999.py:697: UserWarning: Glyph 50836 (\\N{HANGUL SYLLABLE YO}) missing from font(s) DejaVu Sans Mono.\n",
      "  plt.savefig(output_file, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "통합 분석 결과 이미지를 integrated_analysis_result.png에 저장했습니다.\n",
      "통합 분석 데이터를 integrated_analysis_result_data.csv에 저장했습니다.\n",
      "\n",
      "시간에 따른 해류 변화 분석\n",
      "한글 폰트를 찾았습니다: C:/Windows/Fonts/malgun.ttf\n",
      "- 총 4532544개의 해류 데이터 포인트\n",
      "- 기간: 2024-01-01 00:00:00 ~ 2024-12-31 23:00:00\n",
      "해류 시계열 분석 결과를 current_timeseries_analysis.png에 저장했습니다.\n",
      "\n",
      "한글 폰트가 성공적으로 적용되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.quiver import Quiver\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# 한글 폰트 설정 함수\n",
    "def set_korean_font():\n",
    "    \"\"\"\n",
    "    한글 폰트 설정을 위한 함수\n",
    "    시스템에 설치된 한글 폰트를 찾아 설정\n",
    "    \"\"\"\n",
    "    # 시스템 폰트 경로 리스트\n",
    "    font_locations = [\n",
    "        # Windows\n",
    "        'C:/Windows/Fonts/malgun.ttf',                # 맑은 고딕\n",
    "        'C:/Windows/Fonts/gulim.ttc',                 # 굴림\n",
    "        'C:/Windows/Fonts/batang.ttc',                # 바탕\n",
    "        'C:/Windows/Fonts/NanumGothic.ttf',           # 나눔 고딕\n",
    "        'C:/Windows/Fonts/NanumBarunGothic.ttf',      # 나눔 바른 고딕\n",
    "        \n",
    "        # macOS\n",
    "        '/Library/Fonts/AppleGothic.ttf',             # Apple 고딕\n",
    "        '/Library/Fonts/NanumGothic.ttf',             # 나눔 고딕\n",
    "        \n",
    "        # Linux\n",
    "        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',  # 나눔 고딕 (Ubuntu)\n",
    "        '/usr/share/fonts/nanum/NanumGothic.ttf',           # 나눔 고딕 (CentOS)\n",
    "    ]\n",
    "    \n",
    "    # 사용 가능한 폰트 확인\n",
    "    font_found = False\n",
    "    \n",
    "    for font_path in font_locations:\n",
    "        if os.path.exists(font_path):\n",
    "            print(f\"한글 폰트를 찾았습니다: {font_path}\")\n",
    "            # 폰트 설정\n",
    "            plt.rcParams['font.family'] = 'sans-serif'\n",
    "            plt.rcParams['font.sans-serif'] = [fm.FontProperties(fname=font_path).get_name(), 'DejaVu Sans']\n",
    "            font_found = True\n",
    "            break\n",
    "    \n",
    "    if not font_found:\n",
    "        print(\"한글 폰트를 찾을 수 없습니다. 기본 폰트를 사용합니다.\")\n",
    "        # 폰트가 없을 경우 기본 설정\n",
    "        plt.rcParams['font.family'] = 'sans-serif'\n",
    "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "    \n",
    "    # 유니코드 마이너스 문제 해결\n",
    "    mpl.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    return font_found\n",
    "\n",
    "def integrated_analysis(base_path, station_grid_file, debris_data_file, current_data_file, \n",
    "                        output_file='integrated_analysis.png', num_days=30):\n",
    "    \"\"\"\n",
    "    선박밀집도, 해류, 해양쓰레기를 통합 분석하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    - base_path: 선박밀집도 데이터 파일이 있는 기본 경로\n",
    "    - station_grid_file: 정점별 가장 가까운 그리드 정보 파일 경로\n",
    "    - debris_data_file: 해양쓰레기 데이터 파일 경로\n",
    "    - current_data_file: 해류 데이터 파일 경로\n",
    "    - output_file: 출력 이미지 파일 경로\n",
    "    - num_days: 누적할 일수 (기본 30일)\n",
    "    \"\"\"\n",
    "    # 한글 폰트 설정\n",
    "    set_korean_font()\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"선박밀집도, 해류, 해양쓰레기 통합 분석을 시작합니다.\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. 해양쓰레기 데이터 로드\n",
    "    print(\"\\n1. 해양쓰레기 데이터 로드\")\n",
    "    debris_data = {}\n",
    "    if os.path.exists(debris_data_file):\n",
    "        debris_df = pd.read_csv(debris_data_file)\n",
    "        \n",
    "        # 개수 또는 무게 정보가 있는지 확인\n",
    "        if '개수' in debris_df.columns:\n",
    "            # 정점별 쓰레기 개수 저장\n",
    "            for _, row in debris_df.iterrows():\n",
    "                debris_data[row['정점명']] = {\n",
    "                    '개수': row['개수'],\n",
    "                    '무게_kg': row['무게_kg'] if '무게_kg' in debris_df.columns else 0\n",
    "                }\n",
    "            \n",
    "            # 개수 범위 설정\n",
    "            min_debris = debris_df['개수'].min()\n",
    "            max_debris = debris_df['개수'].max()\n",
    "            \n",
    "            print(f\"- 해양쓰레기 데이터 로드: 개수 범위 {min_debris}~{max_debris}\")\n",
    "            print(f\"- 총 {len(debris_data)}개의 정점 데이터가 로드되었습니다.\")\n",
    "        else:\n",
    "            print(\"- 해양쓰레기 데이터에 '개수' 컬럼이 없습니다.\")\n",
    "    else:\n",
    "        print(f\"- 경고: 해양쓰레기 데이터 파일이 존재하지 않습니다: {debris_data_file}\")\n",
    "        return\n",
    "    \n",
    "    # 2. 정점별 가장 가까운 그리드 정보 로드\n",
    "    print(\"\\n2. 정점별 가장 가까운 그리드 정보 로드\")\n",
    "    station_grids = {}\n",
    "    station_locations = {}\n",
    "    \n",
    "    if os.path.exists(station_grid_file):\n",
    "        station_grid_data = pd.read_csv(station_grid_file)\n",
    "        for _, row in station_grid_data.iterrows():\n",
    "            station_grids[row['정점명']] = row['가장_가까운_그리드']\n",
    "            \n",
    "            # 정점 위치 정보도 저장 (있는 경우)\n",
    "            if '위도' in station_grid_data.columns and '경도' in station_grid_data.columns:\n",
    "                station_locations[row['정점명']] = (row['위도'], row['경도'])\n",
    "                \n",
    "        print(f\"- 해양쓰레기 정점 그리드 {len(station_grids)}개를 로드했습니다.\")\n",
    "    else:\n",
    "        print(f\"- 경고: 정점 그리드 파일이 존재하지 않습니다: {station_grid_file}\")\n",
    "        return\n",
    "    \n",
    "    # 3. 해류 데이터 로드\n",
    "    print(\"\\n3. 해류 데이터 로드\")\n",
    "    if os.path.exists(current_data_file):\n",
    "        current_df = pd.read_csv(current_data_file)\n",
    "        \n",
    "        # datetime 문자열을 datetime 객체로 변환\n",
    "        current_df['datetime'] = pd.to_datetime(current_df['datetime'])\n",
    "        \n",
    "        print(f\"- 해류 데이터 로드: 총 {len(current_df)}개 데이터 포인트\")\n",
    "        print(f\"- 데이터 기간: {current_df['datetime'].min()} ~ {current_df['datetime'].max()}\")\n",
    "        \n",
    "        # 해류 방향(current_dir)과 속도(current_speed) 확인\n",
    "        print(f\"- 해류 방향 범위: {current_df['current_dir'].min()}° ~ {current_df['current_dir'].max()}°\")\n",
    "        print(f\"- 해류 속도 범위: {current_df['current_speed'].min()} ~ {current_df['current_speed'].max()} 단위\")\n",
    "        \n",
    "        # 사용 가능한 위경도 범위 확인\n",
    "        lon_range = (current_df['pre_lon'].min(), current_df['pre_lon'].max())\n",
    "        lat_range = (current_df['pre_lat'].min(), current_df['pre_lat'].max())\n",
    "        print(f\"- 위경도 범위: 경도 {lon_range}, 위도 {lat_range}\")\n",
    "    else:\n",
    "        print(f\"- 경고: 해류 데이터 파일이 존재하지 않습니다: {current_data_file}\")\n",
    "        current_df = None\n",
    "    \n",
    "    # 4. 선박밀집도 데이터 누적 계산\n",
    "    print(\"\\n4. 선박밀집도 데이터 누적 계산\")\n",
    "    \n",
    "    # 시작 날짜 설정 (예: 2023년 1월 1일)\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    \n",
    "    # 모든 시간대 포맷 (00시부터 23시까지)\n",
    "    hours = [f\"{h:02d}00\" for h in range(24)]\n",
    "    \n",
    "    # 모든 파일 경로 수집\n",
    "    file_paths = []\n",
    "    \n",
    "    for day in range(num_days):\n",
    "        date = start_date + timedelta(days=day)\n",
    "        date_formatted = date.strftime('%Y%m%d')\n",
    "        \n",
    "        for hour in hours:\n",
    "            file_pattern = os.path.join(base_path, f\"sden_{date_formatted}{hour}_grid3.csv\")\n",
    "            \n",
    "            if os.path.exists(file_pattern):\n",
    "                datetime_obj = datetime.strptime(f\"{date_formatted}{hour}\", '%Y%m%d%H%M')\n",
    "                file_paths.append((datetime_obj, file_pattern))\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(\"- 선박밀집도 데이터 파일을 찾을 수 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 시간 순으로 정렬\n",
    "    file_paths.sort(key=lambda x: x[0])\n",
    "    print(f\"- 총 {len(file_paths)}개 시간대의 선박밀집도 데이터를 분석합니다.\")\n",
    "    \n",
    "    # 첫 번째 파일로 그리드 위치 정보 추출\n",
    "    grid_locations = {}\n",
    "    first_data = pd.read_csv(file_paths[0][1])\n",
    "    \n",
    "    for _, row in first_data.iterrows():\n",
    "        try:\n",
    "            grid_id = row['격자번호']\n",
    "            lat_lon = row['위경도'].split(', ')\n",
    "            lat = float(lat_lon[0])\n",
    "            lon = float(lat_lon[1])\n",
    "            grid_locations[grid_id] = (lat, lon)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"- 총 {len(grid_locations)}개의 그리드 위치 정보를 추출했습니다.\")\n",
    "    \n",
    "    # 누적 선박밀집도 계산\n",
    "    cumulative_density = {}\n",
    "    \n",
    "    print(\"- 선박밀집도 데이터 누적 계산 중...\")\n",
    "    for i, (datetime_obj, file_path) in enumerate(file_paths):\n",
    "        if i % 24 == 0:  # 하루에 24개 시간대가 있으므로 진행상황 표시\n",
    "            print(f\"  처리 중: {datetime_obj.strftime('%Y-%m-%d %H:%M')} ({i+1}/{len(file_paths)})\")\n",
    "            \n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            \n",
    "            for _, row in data.iterrows():\n",
    "                try:\n",
    "                    grid_id = row['격자번호']\n",
    "                    density = row['밀집도(%)']\n",
    "                    traffic = row['교통량(척)']\n",
    "                    \n",
    "                    # 누적 선박밀집도 및 교통량 계산\n",
    "                    if grid_id not in cumulative_density:\n",
    "                        cumulative_density[grid_id] = {\n",
    "                            '누적_밀집도': 0,\n",
    "                            '누적_교통량': 0,\n",
    "                            '데이터_수': 0\n",
    "                        }\n",
    "                    \n",
    "                    cumulative_density[grid_id]['누적_밀집도'] += density\n",
    "                    cumulative_density[grid_id]['누적_교통량'] += traffic\n",
    "                    cumulative_density[grid_id]['데이터_수'] += 1\n",
    "                except:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"  파일 처리 오류: {file_path}, 오류: {str(e)}\")\n",
    "    \n",
    "    # 평균 선박밀집도 계산\n",
    "    for grid_id, data in cumulative_density.items():\n",
    "        if data['데이터_수'] > 0:\n",
    "            data['평균_밀집도'] = data['누적_밀집도'] / data['데이터_수']\n",
    "            data['평균_교통량'] = data['누적_교통량'] / data['데이터_수']\n",
    "        else:\n",
    "            data['평균_밀집도'] = 0\n",
    "            data['평균_교통량'] = 0\n",
    "    \n",
    "    # 최대 누적 밀집도 찾기\n",
    "    max_cumulative_density = max([data['누적_밀집도'] for data in cumulative_density.values()])\n",
    "    print(f\"- 최대 누적 선박밀집도: {max_cumulative_density:.2f}\")\n",
    "    \n",
    "    # 5. 정점별 선박밀집도, 해류, 쓰레기 데이터 통합\n",
    "    print(\"\\n5. 정점별 선박밀집도, 해류, 쓰레기 데이터 통합\")\n",
    "    \n",
    "    # 해양쓰레기 정점 통합 정보\n",
    "    station_integrated_data = []\n",
    "    \n",
    "    for station, grid_id in station_grids.items():\n",
    "        if station in debris_data and grid_id in cumulative_density:\n",
    "            # 선박밀집도 정보\n",
    "            density_data = cumulative_density[grid_id]\n",
    "            cumulative_density_value = density_data['누적_밀집도']\n",
    "            avg_density = density_data['평균_밀집도']\n",
    "            cumulative_traffic = density_data['누적_교통량']\n",
    "            avg_traffic = density_data['평균_교통량']\n",
    "            \n",
    "            # 위경도 정보\n",
    "            if station in station_locations:\n",
    "                lat, lon = station_locations[station]\n",
    "            elif grid_id in grid_locations:\n",
    "                lat, lon = grid_locations[grid_id]\n",
    "            else:\n",
    "                continue  # 위치 정보가 없으면 건너뜀\n",
    "                \n",
    "            # 해류 정보\n",
    "            current_info = {\n",
    "                'avg_speed': None,\n",
    "                'avg_direction': None,\n",
    "                'max_speed': None\n",
    "            }\n",
    "            \n",
    "            if current_df is not None:\n",
    "                # 가장 가까운 해류 데이터 찾기 (위경도 기준)\n",
    "                # 실제 구현에서는 더 복잡한 로직이 필요할 수 있음\n",
    "                # 예: 특정 반경 내의 모든 해류 데이터 평균 계산\n",
    "                \n",
    "                # 위경도 차이를 기준으로 가장 가까운 해류 데이터 포인트 찾기\n",
    "                current_df['distance'] = np.sqrt(\n",
    "                    (current_df['pre_lat'] - lat)**2 + \n",
    "                    (current_df['pre_lon'] - lon)**2\n",
    "                )\n",
    "                \n",
    "                # 가장 가까운 10개 포인트 선택\n",
    "                nearest_currents = current_df.nsmallest(10, 'distance')\n",
    "                \n",
    "                if not nearest_currents.empty:\n",
    "                    current_info['avg_speed'] = nearest_currents['current_speed'].mean()\n",
    "                    \n",
    "                    # 방향은 원형 데이터이므로 평균 계산에 주의\n",
    "                    # 단순화를 위해 산술 평균 사용\n",
    "                    current_info['avg_direction'] = nearest_currents['current_dir'].mean()\n",
    "                    current_info['max_speed'] = nearest_currents['current_speed'].max()\n",
    "            \n",
    "            # 데이터 통합\n",
    "            station_integrated_data.append({\n",
    "                '정점명': station,\n",
    "                '위도': lat,\n",
    "                '경도': lon,\n",
    "                '쓰레기_개수': debris_data[station]['개수'],\n",
    "                '쓰레기_무게_kg': debris_data[station]['무게_kg'],\n",
    "                '누적_선박밀집도': cumulative_density_value,\n",
    "                '평균_선박밀집도': avg_density,\n",
    "                '누적_교통량': cumulative_traffic,\n",
    "                '평균_교통량': avg_traffic,\n",
    "                '해류_평균속도': current_info['avg_speed'],\n",
    "                '해류_평균방향': current_info['avg_direction'],\n",
    "                '해류_최대속도': current_info['max_speed']\n",
    "            })\n",
    "    \n",
    "    if not station_integrated_data:\n",
    "        print(\"- 통합 가능한 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 통합 데이터 DataFrame 생성\n",
    "    integrated_df = pd.DataFrame(station_integrated_data)\n",
    "    print(f\"- 총 {len(integrated_df)}개 정점에 대해 통합 데이터를 생성했습니다.\")\n",
    "    \n",
    "    # 상관관계 분석\n",
    "    print(\"\\n6. 상관관계 분석\")\n",
    "    \n",
    "    # 쓰레기 양과 다른 변수들 사이의 상관관계 계산\n",
    "    correlations = {}\n",
    "    for column in ['누적_선박밀집도', '평균_선박밀집도', '누적_교통량', '평균_교통량']:\n",
    "        if column in integrated_df.columns:\n",
    "            corr = integrated_df['쓰레기_개수'].corr(integrated_df[column])\n",
    "            correlations[column] = corr\n",
    "            print(f\"- {column}와(과) 쓰레기 개수의 상관계수: {corr:.3f}\")\n",
    "    \n",
    "    # 해류 데이터가 있는 경우 해류 변수와의 상관관계도 계산\n",
    "    if '해류_평균속도' in integrated_df.columns and integrated_df['해류_평균속도'].notna().any():\n",
    "        for column in ['해류_평균속도', '해류_최대속도']:\n",
    "            if column in integrated_df.columns:\n",
    "                corr = integrated_df['쓰레기_개수'].corr(integrated_df[column])\n",
    "                correlations[column] = corr\n",
    "                print(f\"- {column}와(과) 쓰레기 개수의 상관계수: {corr:.3f}\")\n",
    "    \n",
    "    # 7. 통합 시각화\n",
    "    print(\"\\n7. 통합 시각화\")\n",
    "    \n",
    "    # 큰 그림 생성 (2x2 그리드로 구성)\n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "    \n",
    "    # 그리드 설정\n",
    "    gs = fig.add_gridspec(2, 2, width_ratios=[1.5, 1], height_ratios=[1.5, 1])\n",
    "    \n",
    "    # 1. 메인 지도 (누적 선박밀집도 + 해양쓰레기 + 해류)\n",
    "    ax_map = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    # 커스텀 컬러맵 생성\n",
    "    colors = [(0, 0, 1), (0, 1, 0), (1, 1, 0), (1, 0, 0)]  # 파랑, 초록, 노랑, 빨강\n",
    "    cmap_name = 'ship_density_cmap'\n",
    "    cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "    \n",
    "    # 해양쓰레기 양에 따른 색상 정의 (파랑, 녹색, 빨강)\n",
    "    debris_colors = {\n",
    "        'low': (0, 0, 1),     # 파랑\n",
    "        'medium': (0, 0.8, 0), # 녹색\n",
    "        'high': (1, 0, 0)      # 빨강\n",
    "    }\n",
    "    \n",
    "    # 1.1 선박밀집도 데이터 그리기\n",
    "    x = []  # 경도\n",
    "    y = []  # 위도\n",
    "    s = []  # 마커 크기 (평균 교통량)\n",
    "    c = []  # 색상 (누적 밀집도)\n",
    "    \n",
    "    for grid_id, data in cumulative_density.items():\n",
    "        if grid_id in grid_locations:\n",
    "            lat, lon = grid_locations[grid_id]\n",
    "            y.append(lat)\n",
    "            x.append(lon)\n",
    "            s.append(max(data['평균_교통량'] / 5, 10))  # 평균 교통량에 따른 마커 크기 조정, 최소 크기 10\n",
    "            c.append(data['누적_밀집도'])\n",
    "    \n",
    "    # 선박밀집도 산점도 그리기\n",
    "    scatter = ax_map.scatter(x, y, s=s, c=c, cmap=cm, alpha=0.7, \n",
    "                          vmin=0, vmax=max_cumulative_density, edgecolors='k', linewidths=0.5)\n",
    "    \n",
    "    # 1.2 쓰레기 양 표시\n",
    "    # 정점 데이터를 3등분하여 색상 결정\n",
    "    if integrated_df['쓰레기_개수'].nunique() >= 3:\n",
    "        # 표시되는 정점들의 쓰레기 양 목록 추출\n",
    "        sorted_amounts = sorted(integrated_df['쓰레기_개수'])\n",
    "        total_points = len(sorted_amounts)\n",
    "        \n",
    "        # 균등하게 3분할하는 임계값 설정\n",
    "        third_index = total_points // 3\n",
    "        two_thirds_index = 2 * third_index\n",
    "        \n",
    "        low_threshold = sorted_amounts[third_index] if third_index < total_points else min(sorted_amounts)\n",
    "        high_threshold = sorted_amounts[two_thirds_index] if two_thirds_index < total_points else max(sorted_amounts)\n",
    "    else:\n",
    "        # 데이터 포인트가 적은 경우 균등 분할\n",
    "        min_debris = integrated_df['쓰레기_개수'].min()\n",
    "        max_debris = integrated_df['쓰레기_개수'].max()\n",
    "        range_size = (max_debris - min_debris) / 3\n",
    "        low_threshold = min_debris + range_size\n",
    "        high_threshold = max_debris - range_size\n",
    "    \n",
    "    # 각 카테고리에 몇 개의 정점이 포함되는지 계산\n",
    "    low_count = sum(1 for val in integrated_df['쓰레기_개수'] if val <= low_threshold)\n",
    "    medium_count = sum(1 for val in integrated_df['쓰레기_개수'] if low_threshold < val <= high_threshold)\n",
    "    high_count = sum(1 for val in integrated_df['쓰레기_개수'] if val > high_threshold)\n",
    "    \n",
    "    # 박스 크기 설정\n",
    "    box_size = 0.08\n",
    "    \n",
    "    # 정점별 박스 색상 설정\n",
    "    integrated_df['쓰레기_카테고리'] = pd.cut(\n",
    "        integrated_df['쓰레기_개수'],\n",
    "        bins=[0, low_threshold, high_threshold, float('inf')],\n",
    "        labels=['low', 'medium', 'high']\n",
    "    )\n",
    "    \n",
    "    # 정점 그리기\n",
    "    for _, row in integrated_df.iterrows():\n",
    "        # 쓰레기 양에 따라 색상 결정\n",
    "        category = row['쓰레기_카테고리']\n",
    "        color = debris_colors[category]\n",
    "        face_color = (*color, 0.3)\n",
    "        \n",
    "        # 네모 그리기\n",
    "        rect = patches.Rectangle(\n",
    "            (row['경도'] - box_size/2, row['위도'] - box_size/2), box_size, box_size, \n",
    "            linewidth=2, edgecolor=color, facecolor=face_color\n",
    "        )\n",
    "        ax_map.add_patch(rect)\n",
    "        \n",
    "        # 정점 이름 표시\n",
    "        ax_map.text(row['경도'], row['위도'] + box_size/2, row['정점명'], \n",
    "                 fontsize=8, color='black', ha='center', va='bottom',\n",
    "                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # 1.3 해류 벡터 표시 (시간에 따른 평균 해류)\n",
    "    if current_df is not None:\n",
    "        # 해류 데이터를 그리드화하여 표시\n",
    "        grid_size = 0.5  # 그리드 크기 (도 단위)\n",
    "        \n",
    "        # 그리드 생성\n",
    "        lon_grid = np.arange(np.floor(min(x)) - 1, np.ceil(max(x)) + 1, grid_size)\n",
    "        lat_grid = np.arange(np.floor(min(y)) - 1, np.ceil(max(y)) + 1, grid_size)\n",
    "        \n",
    "        # 각 그리드 셀에 대한 해류 평균 계산\n",
    "        current_grid = {}\n",
    "        \n",
    "        for i, lon in enumerate(lon_grid[:-1]):\n",
    "            for j, lat in enumerate(lat_grid[:-1]):\n",
    "                # 그리드 셀 범위\n",
    "                lon_min, lon_max = lon, lon_grid[i + 1]\n",
    "                lat_min, lat_max = lat, lat_grid[j + 1]\n",
    "                \n",
    "                # 그리드 셀 내의 해류 데이터 찾기\n",
    "                cell_data = current_df[\n",
    "                    (current_df['pre_lon'] >= lon_min) & (current_df['pre_lon'] < lon_max) &\n",
    "                    (current_df['pre_lat'] >= lat_min) & (current_df['pre_lat'] < lat_max)\n",
    "                ]\n",
    "                \n",
    "                if not cell_data.empty:\n",
    "                    # 평균 해류 계산\n",
    "                    avg_dir = cell_data['current_dir'].mean()\n",
    "                    avg_speed = cell_data['current_speed'].mean()\n",
    "                    \n",
    "                    # 각도를 벡터 성분으로 변환 (방향은 해양학 표기법: 0도는 북쪽, 시계방향으로 증가)\n",
    "                    u = -avg_speed * np.sin(np.radians(avg_dir))  # 동쪽 성분 (음수는 서쪽)\n",
    "                    v = -avg_speed * np.cos(np.radians(avg_dir))  # 북쪽 성분 (음수는 남쪽)\n",
    "                    \n",
    "                    # 그리드 셀 중심 계산\n",
    "                    cell_center = ((lon_min + lon_max) / 2, (lat_min + lat_max) / 2)\n",
    "                    \n",
    "                    current_grid[cell_center] = (u, v, avg_speed)\n",
    "        \n",
    "        # 해류 벡터 그리기\n",
    "        for (center_lon, center_lat), (u, v, speed) in current_grid.items():\n",
    "            # 화살표 길이 스케일 조정 (해류 속도에 비례)\n",
    "            scale = 0.1 * speed / max(current_df['current_speed'].max(), 1)  # 최대 화살표 길이 조정\n",
    "            \n",
    "            # 화살표 색상 (해류 속도에 따라)\n",
    "            arrow_color = plt.cm.viridis(speed / max(current_df['current_speed'].max(), 1))\n",
    "            \n",
    "            # 화살표 그리기\n",
    "            ax_map.arrow(\n",
    "                center_lon, center_lat, \n",
    "                u * scale, v * scale, \n",
    "                head_width=0.05, head_length=0.1, \n",
    "                fc=arrow_color, ec=arrow_color, alpha=0.7\n",
    "            )\n",
    "    \n",
    "    # 범례 요소 생성\n",
    "    low_patch = patches.Rectangle((0, 0), 1, 1, linewidth=1, edgecolor=debris_colors['low'], facecolor=(*debris_colors['low'], 0.3))\n",
    "    med_patch = patches.Rectangle((0, 0), 1, 1, linewidth=1, edgecolor=debris_colors['medium'], facecolor=(*debris_colors['medium'], 0.3))\n",
    "    high_patch = patches.Rectangle((0, 0), 1, 1, linewidth=1, edgecolor=debris_colors['high'], facecolor=(*debris_colors['high'], 0.3))\n",
    "    \n",
    "    # 화살표 범례 (해류)\n",
    "    if current_df is not None:\n",
    "        arrow_leg = ax_map.arrow(0, 0, 0.1, 0, head_width=0.05, head_length=0.1, fc='purple', ec='purple')\n",
    "    \n",
    "    # 범례 추가\n",
    "    legend_elements = [\n",
    "        low_patch, med_patch, high_patch\n",
    "    ]\n",
    "    \n",
    "    legend_labels = [\n",
    "        f'적은 쓰레기 (≤{low_threshold}개, {low_count}개 정점)', \n",
    "        f'중간 쓰레기 ({low_threshold}~{high_threshold}개, {medium_count}개 정점)', \n",
    "        f'많은 쓰레기 (>{high_threshold}개, {high_count}개 정점)'\n",
    "    ]\n",
    "    \n",
    "    if current_df is not None:\n",
    "        legend_elements.append(arrow_leg)\n",
    "        legend_labels.append('해류 방향 및 세기')\n",
    "    \n",
    "    ax_map.legend(\n",
    "        legend_elements, legend_labels,\n",
    "        loc='upper left', fontsize=10\n",
    "    )\n",
    "    \n",
    "    # 제목 및 레이블\n",
    "    ax_map.set_title(f'{num_days}일간 누적 선박밀집도와 해양쓰레기 비교 ({start_date.strftime(\"%Y-%m-%d\")}부터)', fontsize=14)\n",
    "    ax_map.set_xlabel('경도', fontsize=12)\n",
    "    ax_map.set_ylabel('위도', fontsize=12)\n",
    "    \n",
    "    # 컬러바 추가\n",
    "    cbar = fig.colorbar(scatter, ax=ax_map)\n",
    "    cbar.set_label('누적 선박밀집도')\n",
    "    \n",
    "    # 한국 해안선 형태를 대략적으로 표현하기 위한 좌표 범위 설정\n",
    "    ax_map.set_xlim([126, 130])\n",
    "    ax_map.set_ylim([34, 38])\n",
    "    \n",
    "    # 그리드 추가\n",
    "    ax_map.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # 상관관계 정보 추가\n",
    "    corr_text = '\\n'.join([f\"{k}: {v:.3f}\" for k, v in correlations.items()])\n",
    "    ax_map.text(\n",
    "        0.02, 0.05, \n",
    "        f'쓰레기 양과의 상관계수:\\n{corr_text}',\n",
    "        transform=ax_map.transAxes,\n",
    "        fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "    )\n",
    "    \n",
    "    # 2. 선박밀집도-쓰레기 양 산점도\n",
    "    ax_scatter = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    # 산점도 데이터 준비\n",
    "    scatter_x = integrated_df['누적_선박밀집도']\n",
    "    scatter_y = integrated_df['쓰레기_개수']\n",
    "    \n",
    "    # 색상 설정\n",
    "    scatter_colors = [debris_colors[cat] for cat in integrated_df['쓰레기_카테고리']]\n",
    "    \n",
    "    # 산점도 그리기\n",
    "    ax_scatter.scatter(scatter_x, scatter_y, c=scatter_colors, alpha=0.7, s=80)\n",
    "    \n",
    "    # 회귀선 추가\n",
    "    if len(scatter_x) > 1:\n",
    "        z = np.polyfit(scatter_x, scatter_y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax_scatter.plot(sorted(scatter_x), p(sorted(scatter_x)), \"r--\", alpha=0.5)\n",
    "        \n",
    "        # 회귀식 텍스트 추가\n",
    "        eq_text = f'y = {z[0]:.2f}x + {z[1]:.2f}, R² = {correlations[\"누적_선박밀집도\"]**2:.2f}'\n",
    "        ax_scatter.text(0.05, 0.95, eq_text, transform=ax_scatter.transAxes, \n",
    "                     fontsize=10, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # 각 정점에 레이블 추가\n",
    "    for i, row in integrated_df.iterrows():\n",
    "        ax_scatter.annotate(row['정점명'], \n",
    "                         (row['누적_선박밀집도'], row['쓰레기_개수']),\n",
    "                         fontsize=8, alpha=0.7,\n",
    "                         xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    # 축 레이블 및 제목\n",
    "    ax_scatter.set_xlabel('누적 선박밀집도', fontsize=12)\n",
    "    ax_scatter.set_ylabel('쓰레기 개수', fontsize=12)\n",
    "    ax_scatter.set_title('선박밀집도와 쓰레기 양의 관계', fontsize=14)\n",
    "    ax_scatter.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 3. 해류 속도-쓰레기 양 산점도\n",
    "    ax_current = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    # 해류 데이터가 있는 경우에만 그리기\n",
    "    if current_df is not None and '해류_평균속도' in integrated_df.columns and integrated_df['해류_평균속도'].notna().any():\n",
    "        # 산점도 데이터 준비\n",
    "        current_x = integrated_df['해류_평균속도']\n",
    "        current_y = integrated_df['쓰레기_개수']\n",
    "        \n",
    "        # 산점도 그리기\n",
    "        ax_current.scatter(current_x, current_y, c=scatter_colors, alpha=0.7, s=80)\n",
    "        \n",
    "        # 회귀선 추가\n",
    "        if len(current_x) > 1 and not current_x.isna().all():\n",
    "            valid_indices = ~current_x.isna() & ~current_y.isna()\n",
    "            if sum(valid_indices) > 1:  # 최소 2개 이상의 유효한 데이터 포인트 필요\n",
    "                valid_x = current_x[valid_indices]\n",
    "                valid_y = current_y[valid_indices]\n",
    "                \n",
    "                z = np.polyfit(valid_x, valid_y, 1)\n",
    "                p = np.poly1d(z)\n",
    "                \n",
    "                x_range = np.linspace(min(valid_x), max(valid_x), 100)\n",
    "                ax_current.plot(x_range, p(x_range), \"r--\", alpha=0.5)\n",
    "                \n",
    "                # 상관계수 계산 및 회귀식 텍스트 추가\n",
    "                corr_current = valid_x.corr(valid_y)\n",
    "                eq_text = f'y = {z[0]:.2f}x + {z[1]:.2f}, R² = {corr_current**2:.2f}'\n",
    "                ax_current.text(0.05, 0.95, eq_text, transform=ax_current.transAxes, \n",
    "                             fontsize=10, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        # 각 정점에 레이블 추가\n",
    "        for i, row in integrated_df.iterrows():\n",
    "            if pd.notna(row['해류_평균속도']):\n",
    "                ax_current.annotate(row['정점명'], \n",
    "                                 (row['해류_평균속도'], row['쓰레기_개수']),\n",
    "                                 fontsize=8, alpha=0.7,\n",
    "                                 xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "        # 축 레이블 및 제목\n",
    "        ax_current.set_xlabel('해류 평균 속도', fontsize=12)\n",
    "        ax_current.set_ylabel('쓰레기 개수', fontsize=12)\n",
    "        ax_current.set_title('해류 속도와 쓰레기 양의 관계', fontsize=14)\n",
    "        ax_current.grid(True, linestyle='--', alpha=0.3)\n",
    "    else:\n",
    "        ax_current.text(0.5, 0.5, '해류 데이터가 충분하지 않습니다', \n",
    "                     ha='center', va='center', fontsize=14)\n",
    "        ax_current.axis('off')\n",
    "    \n",
    "    # 4. 다변량 분석 결과 표시\n",
    "    ax_multi = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    # 다변량 회귀 분석\n",
    "    if len(integrated_df) > 3:  # 최소 데이터 포인트 필요\n",
    "        try:\n",
    "            # 입력 변수 선택 (누적_선박밀집도, 해류_평균속도)\n",
    "            X_vars = ['누적_선박밀집도']\n",
    "            \n",
    "            if '해류_평균속도' in integrated_df.columns and integrated_df['해류_평균속도'].notna().any():\n",
    "                X_vars.append('해류_평균속도')\n",
    "            \n",
    "            # 결측치 처리\n",
    "            analysis_df = integrated_df.dropna(subset=X_vars + ['쓰레기_개수'])\n",
    "            \n",
    "            if len(analysis_df) > 3:  # 유효한 데이터가 충분한지 확인\n",
    "                X = analysis_df[X_vars]\n",
    "                y = analysis_df['쓰레기_개수']\n",
    "                \n",
    "                # 다변량 회귀 분석 (단순 구현)\n",
    "                X = sm.add_constant(X)  # 상수항 추가\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                \n",
    "                # 결과 표시\n",
    "                summary_text = f\"다변량 회귀 분석 결과:\\n\\n\"\n",
    "                summary_text += f\"R-squared: {model.rsquared:.3f}\\n\"\n",
    "                summary_text += f\"Adjusted R-squared: {model.rsquared_adj:.3f}\\n\\n\"\n",
    "                summary_text += \"계수:\\n\"\n",
    "                \n",
    "                for i, var in enumerate(['상수항'] + X_vars):\n",
    "                    summary_text += f\"{var}: {model.params[i]:.4f} (p={model.pvalues[i]:.4f})\\n\"\n",
    "                \n",
    "                if len(X_vars) > 1:\n",
    "                    # 상대적 중요도 계산\n",
    "                    importance = abs(model.params[1:] * X.std()[1:])\n",
    "                    importance = importance / importance.sum() * 100\n",
    "                    \n",
    "                    summary_text += \"\\n상대적 중요도 (%):\\n\"\n",
    "                    for i, var in enumerate(X_vars):\n",
    "                        summary_text += f\"{var}: {importance[i]:.1f}%\\n\"\n",
    "                \n",
    "                # 텍스트 표시\n",
    "                ax_multi.text(0.05, 0.95, summary_text, transform=ax_multi.transAxes,\n",
    "                           fontsize=10, va='top', family='monospace')\n",
    "                ax_multi.axis('off')\n",
    "            else:\n",
    "                ax_multi.text(0.5, 0.5, '다변량 분석을 위한 유효한 데이터가 부족합니다', \n",
    "                           ha='center', va='center', fontsize=12)\n",
    "                ax_multi.axis('off')\n",
    "        except Exception as e:\n",
    "            print(f\"다변량 분석 오류: {str(e)}\")\n",
    "            ax_multi.text(0.5, 0.5, f'다변량 분석 오류: {str(e)}', \n",
    "                       ha='center', va='center', fontsize=10, wrap=True)\n",
    "            ax_multi.axis('off')\n",
    "    else:\n",
    "        ax_multi.text(0.5, 0.5, '다변량 분석을 위한 데이터가 부족합니다', \n",
    "                   ha='center', va='center', fontsize=14)\n",
    "        ax_multi.axis('off')\n",
    "    \n",
    "    # 전체 제목\n",
    "    fig.suptitle(f'선박밀집도, 해류, 해양쓰레기 통합 분석', fontsize=16, y=0.98)\n",
    "    \n",
    "    # 여백 조정\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    \n",
    "    # 이미지 저장\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"통합 분석 결과 이미지를 {output_file}에 저장했습니다.\")\n",
    "    \n",
    "    # CSV 파일로 통합 데이터 저장\n",
    "    output_csv = output_file.replace('.png', '_data.csv')\n",
    "    integrated_df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"통합 분석 데이터를 {output_csv}에 저장했습니다.\")\n",
    "    \n",
    "    plt.close()\n",
    "    return integrated_df\n",
    "\n",
    "# 추가 함수: 시간에 따른 해류 변화 분석\n",
    "def analyze_current_time_series(current_data_file, output_file='current_timeseries.png'):\n",
    "    \"\"\"\n",
    "    시간에 따른 해류 변화를 분석하고 시각화\n",
    "    \n",
    "    Parameters:\n",
    "    - current_data_file: 해류 데이터 파일 경로\n",
    "    - output_file: 출력 이미지 파일 경로\n",
    "    \"\"\"\n",
    "    print(\"\\n시간에 따른 해류 변화 분석\")\n",
    "    \n",
    "    if not os.path.exists(current_data_file):\n",
    "        print(f\"경고: 해류 데이터 파일이 존재하지 않습니다: {current_data_file}\")\n",
    "        return\n",
    "    \n",
    "    # 한글 폰트 설정 (이미 메인에서 설정되었을 수 있지만 안전을 위해 재설정)\n",
    "    set_korean_font()\n",
    "    \n",
    "    # 데이터 로드\n",
    "    current_df = pd.read_csv(current_data_file)\n",
    "    current_df['datetime'] = pd.to_datetime(current_df['datetime'])\n",
    "    \n",
    "    # 데이터 확인\n",
    "    print(f\"- 총 {len(current_df)}개의 해류 데이터 포인트\")\n",
    "    print(f\"- 기간: {current_df['datetime'].min()} ~ {current_df['datetime'].max()}\")\n",
    "    \n",
    "    # 특정 위치에서의 시계열 분석\n",
    "    # 해안에 가까운 위치를 몇 개 선택\n",
    "    coastal_points = []\n",
    "    \n",
    "    # 그리드 생성 후 해안에 가까운 포인트 선택\n",
    "    lon_grid = np.linspace(125, 130, 10)\n",
    "    lat_grid = np.linspace(33, 38, 10)\n",
    "    \n",
    "    for lon in lon_grid[0:3]:  # 서쪽 해안에 가까운 지점\n",
    "        for lat in lat_grid:\n",
    "            coastal_points.append((lon, lat))\n",
    "    \n",
    "    # 각 포인트에서 가장 가까운 해류 데이터 시계열 분석\n",
    "    point_timeseries = {}\n",
    "    \n",
    "    for point_idx, (target_lon, target_lat) in enumerate(coastal_points[:5]):  # 최대 5개 포인트만 분석\n",
    "        # 해당 포인트에서 가장 가까운 해류 데이터 찾기\n",
    "        current_df['distance'] = np.sqrt(\n",
    "            (current_df['pre_lon'] - target_lon)**2 + \n",
    "            (current_df['pre_lat'] - target_lat)**2\n",
    "        )\n",
    "        \n",
    "        closest_idx = current_df['distance'].idxmin()\n",
    "        closest_lon = current_df.loc[closest_idx, 'pre_lon']\n",
    "        closest_lat = current_df.loc[closest_idx, 'pre_lat']\n",
    "        \n",
    "        # 선택된 위치의 모든 시간대 데이터 추출\n",
    "        point_data = current_df[\n",
    "            (np.isclose(current_df['pre_lon'], closest_lon, atol=0.01)) & \n",
    "            (np.isclose(current_df['pre_lat'], closest_lat, atol=0.01))\n",
    "        ].copy()\n",
    "        \n",
    "        if len(point_data) > 0:\n",
    "            point_data = point_data.sort_values('datetime')\n",
    "            \n",
    "            # 고유한 ID 생성\n",
    "            point_id = f\"Point_{point_idx+1}_({closest_lon:.2f}, {closest_lat:.2f})\"\n",
    "            point_timeseries[point_id] = point_data\n",
    "    \n",
    "    if not point_timeseries:\n",
    "        print(\"- 시계열 분석을 위한 데이터가 충분하지 않습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(len(point_timeseries), 2, figsize=(15, 5 * len(point_timeseries)))\n",
    "    \n",
    "    if len(point_timeseries) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (point_id, data) in enumerate(point_timeseries.items()):\n",
    "        # 해류 속도 시계열\n",
    "        ax_speed = axes[i][0]\n",
    "        ax_speed.plot(data['datetime'], data['current_speed'], 'b-', linewidth=2)\n",
    "        ax_speed.set_title(f'{point_id} - 해류 속도 변화', fontsize=12)\n",
    "        ax_speed.set_xlabel('날짜', fontsize=10)\n",
    "        ax_speed.set_ylabel('해류 속도', fontsize=10)\n",
    "        ax_speed.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax_speed.xaxis.set_major_formatter(DateFormatter('%m-%d'))\n",
    "        plt.setp(ax_speed.xaxis.get_majorticklabels(), rotation=45)\n",
    "        \n",
    "        # 해류 방향 시계열\n",
    "        ax_dir = axes[i][1]\n",
    "        ax_dir.plot(data['datetime'], data['current_dir'], 'r-', linewidth=2)\n",
    "        ax_dir.set_title(f'{point_id} - 해류 방향 변화', fontsize=12)\n",
    "        ax_dir.set_xlabel('날짜', fontsize=10)\n",
    "        ax_dir.set_ylabel('해류 방향 (도)', fontsize=10)\n",
    "        ax_dir.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax_dir.xaxis.set_major_formatter(DateFormatter('%m-%d'))\n",
    "        plt.setp(ax_dir.xaxis.get_majorticklabels(), rotation=45)\n",
    "        \n",
    "        # 방향은 0-360도 사이의 값이므로 y축 범위 설정\n",
    "        ax_dir.set_ylim([0, 360])\n",
    "        ax_dir.set_yticks(np.arange(0, 361, 45))\n",
    "        ax_dir.set_yticklabels(['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N'])\n",
    "    \n",
    "    # 전체 제목\n",
    "    fig.suptitle('시간에 따른 해류 변화 분석', fontsize=16, y=0.98)\n",
    "    \n",
    "    # 여백 조정\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # 이미지 저장\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"해류 시계열 분석 결과를 {output_file}에 저장했습니다.\")\n",
    "    \n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 한글 폰트 설정\n",
    "    korean_font_available = set_korean_font()\n",
    "    \n",
    "    # 데이터 경로 설정\n",
    "    base_path = r'D:\\marideb\\code\\sden_2023_lv3'  # 선박밀집도 데이터 기본 경로\n",
    "    station_grid_file = 'station_nearest_grid.csv'  # 정점별 가장 가까운 그리드 정보 파일\n",
    "    debris_data_file = r'D:\\marideb\\code\\marideb_location.csv'  # 해양쓰레기 데이터 파일\n",
    "    current_data_file = r'D:\\marideb\\code\\tidal_current_2024.csv'  # 해류 데이터 파일\n",
    "    \n",
    "    # 필요한 패키지 임포트\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    # 1. 통합 분석 수행\n",
    "    integrated_df = integrated_analysis(\n",
    "        base_path, station_grid_file, debris_data_file, current_data_file, \n",
    "        output_file='integrated_analysis_result.png', \n",
    "        num_days=30\n",
    "    )\n",
    "    \n",
    "    # 2. 시간에 따른 해류 변화 분석\n",
    "    analyze_current_time_series(current_data_file, output_file='current_timeseries_analysis.png')\n",
    "    \n",
    "    # 폰트 설정 알림\n",
    "    if korean_font_available:\n",
    "        print(\"\\n한글 폰트가 성공적으로 적용되었습니다.\")\n",
    "    else:\n",
    "        print(\"\\n경고: 한글 폰트를 설정할 수 없어 일부 한글이 깨질 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marideb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
