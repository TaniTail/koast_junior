{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Model Extract :  gdps_ne36 aws 2024040100 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040112 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040200 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040212 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040300 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040312 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040400 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040412 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040500 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040512 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040600 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040612 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040700 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040712 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040800 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040812 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040900 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024040912 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041000 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041012 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041100 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041112 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041200 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041212 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041300 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041312 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041400 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041412 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041500 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041512 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041600 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041612 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041700 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041712 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041800 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041812 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041900 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024041912 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042000 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042012 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042100 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042112 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042200 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042212 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042300 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042312 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042400 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042412 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042500 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042512 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042600 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042612 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042700 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042712 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042800 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042812 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042900 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024042912 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024043000 interval: 3 extractHour: 135\n",
      "- Model Extract :  gdps_ne36 aws 2024043012 interval: 3 extractHour: 135\n"
     ]
    }
   ],
   "source": [
    "#import sqlite3\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import argparse\n",
    "import importlib\n",
    "\n",
    "import _config as cfg\n",
    "\n",
    "\n",
    "# 지점별 데이터 추출\n",
    "\n",
    "def model_extract(modelCode, modelDt, interval, maxHour, stnXyList, obsCode) :\n",
    "    '''\n",
    "    Extracts model data for the specified model code and date, and saves the results to a text file\n",
    "\n",
    "    Parameters:\n",
    "    - modelCode(str): The code of the model to be extracted\n",
    "    - modelDt(datetime): The date and time for which the model data is to be extracted\n",
    "    - interval(int): The time interval for the forecast (in hours)\n",
    "    - maxHour(int): The maximum forecast hour\n",
    "    - stnXyList(list): A list of dictionaries containing station information (station IDs, coordinates)\n",
    "    - obsCode(str): Observation code ('aws', 'asos')\n",
    "    \n",
    "        Returns:\n",
    "        - None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    modelExtractor = importlib.import_module('model_extract.' + modelCode)\n",
    "\n",
    "    modelData = modelExtractor.model_extract(modelDt, interval, maxHour, stnXyList, cfg.PATH_TMP)\n",
    "    if modelData is None :\n",
    "        print(f'[ERROR] {modelCode} model extract failed. {modelDt.strftime(\"%Y%m%d%H\")}')\n",
    "        return False\n",
    "\n",
    "    #txtFile = cfg.PATH_MODEL_EXTRACT_TXT.format(MODEL=modelCode, OBS=obsCode, YYYY=modelDt.strftime('%Y'), TH_HR=interval, FT_HR=maxHour, YYYYMMDDHH=modelDt.strftime('%Y%m%d%H'))\n",
    "    txtFile = cfg.PATH_MODEL_EXTRACT_TXT.format(MODEL=modelCode, OBS=obsCode, YYYY=modelDt.strftime('%Y'), YYYYMMDDHH=modelDt.strftime('%Y%m%d%H'))\n",
    "    txtFileDir = os.path.dirname(txtFile)\n",
    "    if not os.path.isdir(txtFileDir) :\n",
    "        try :\n",
    "            os.makedirs(txtFileDir)\n",
    "        except :\n",
    "            pass\n",
    "    else :\n",
    "        if os.path.exists(txtFile) :\n",
    "            os.remove(txtFile)\n",
    "    \n",
    "\n",
    "    stnIds = []\n",
    "    for stn in stnXyList :\n",
    "        stnIds.append(stn['stn'])\n",
    "    stnIds.sort()\n",
    "\n",
    "    header1 = f\"# INFO, model:{modelCode}, obs:{obsCode}, ymdh:{modelDt.strftime('%Y%m%d%H')}, fcstInterval:{interval}, fcstMaxHour:{maxHour}\"\n",
    "    header2 = \"#   FT  \"\n",
    "    for step in range(interval, maxHour+interval, interval) : \n",
    "        header2 += format(step, \"7d\")\n",
    "    cont = \"\"\n",
    "    for sid in stnIds :\n",
    "        #stnId = str(sid)\n",
    "        cont += format(sid, \"6d\")\n",
    "        cont += \"  \"\n",
    "        for i in range(len(modelData[sid])) :\n",
    "            cont += format(modelData[sid][i], \"7.2f\")\n",
    "        cont += \"\\n\"\n",
    "    \n",
    "    f = open(txtFile, 'w')\n",
    "    f.write(header1)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(header2)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(cont)\n",
    "    f.close()\n",
    "\n",
    "def getStnXyList(model, obs, dt) :\n",
    "    '''\n",
    "    Read file and get station information including coordinates\n",
    "\n",
    "    Parameters:\n",
    "    - model(str): model code\n",
    "    - obs(str): Observation code (aws, asos)\n",
    "    - dt(datetime): datetime for finding a file (KST)\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of dictionaries contains the station ID, latitude, longitude,\n",
    "             and x, y coordinates of the station. If the file does not exist, returns False\n",
    "    '''\n",
    "    \n",
    "    xyfile = cfg.PATH_MODEL_STNXY.format(MODEL=model, OBS=obs, YYYY=dt.strftime('%Y'), YYYYMMDD=dt.strftime('%Y%m%d'))\n",
    "    if os.path.exists(xyfile) == False :\n",
    "        return False\n",
    "    # f.write(f\"{stnXyInfo['stn']},{stnXyInfo['lat']},{stnXyInfo['lon']},{stnXyInfo['x']},{stnXyInfo['y']}\\n\")\n",
    "    stnXyList = []\n",
    "    with open(xyfile, 'r') as f:\n",
    "        # 첫 번째 줄(헤더) 건너뛰기\n",
    "        header = f.readline()\n",
    "        \n",
    "        for line in f:\n",
    "            row = line.split(',')\n",
    "            pt = {\n",
    "                'stn': int(row[0]),\n",
    "                'lat': float(row[1]),\n",
    "                'lon': float(row[2]),\n",
    "                'x': int(row[3]),\n",
    "                'y': int(row[4])\n",
    "            }\n",
    "            stnXyList.append(pt)\n",
    "        \n",
    "\n",
    "    return stnXyList\n",
    "\n",
    "\n",
    "# main\n",
    "if __name__ == '__main__' :\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('--model', required=True, help='gdps_ne36/gdps_n128/rdps_ne36/ldps/ecmf/klfs_ne36/klfs_n128')\n",
    "    # parser.add_argument('--modelTm', required=True, help='yyyymmddhh')\n",
    "    # # parser.add_argument('--fcstInterval', required=True, help='hour')\n",
    "    # # parser.add_argument('--fcstMaxHours', required=True, help='hour')\n",
    "    # parser.add_argument('--obs', required=True, help='asos/aws')\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    \n",
    "    modelcode = 'gdps_ne36'\n",
    "    obscode = 'aws'\n",
    "    \n",
    "    start_date = datetime(2024, 4, 1, 0)  # 2024년 3월 1일 00시\n",
    "    end_date = datetime(2024, 4, 30, 12)   # 2024년 3월 30일 12시\n",
    "    \n",
    "    modeltimes = []\n",
    "    current_time = start_date\n",
    "    \n",
    "    while current_time <= end_date:\n",
    "        modeltimes.append(current_time.strftime('%Y%m%d%H'))\n",
    "        current_time += timedelta(hours=12)\n",
    "    \n",
    "    for modeltime in modeltimes:\n",
    "        \n",
    "    #print(\"- Model Extract : \", args.model, args.obs, args.modelTm, 'fcstInterval:', args.fcstInterval, 'fcstMaxHour:',args.fcstMaxHours)\n",
    "        fcstInterval = cfg.modelConf[modelcode]['fcstInterval']\n",
    "        extractMaxHour = cfg.modelConf[modelcode]['modelExtractHours']\n",
    "        print(\"- Model Extract : \", modelcode, obscode, modeltime, 'interval:', str(fcstInterval), 'extractHour:', str(extractMaxHour))\n",
    "\n",
    "        modelDt = datetime.strptime(modeltime, '%Y%m%d%H')\n",
    "\n",
    "        stnXyList = getStnXyList(modelcode, obscode, modelDt)\n",
    "    \n",
    "        #model_extract(args.model, modelDt, int(args.fcstInterval), int(args.fcstMaxHours), stnXyList, args.obs)\n",
    "        \n",
    "        model_extract(modelcode, modelDt, fcstInterval, extractMaxHour, stnXyList, obscode)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
