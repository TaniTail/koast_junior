{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 import\n",
    "\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import random\n",
    "\n",
    "# 모델 학습에 필요한 토치 관련 패키지 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader, random_split \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check device\n",
    "\n",
    "def check_gpu_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        print(f'GPU 사용: {torch.cuda.get_device_name(device)}')\n",
    "    else:\n",
    "        print('GPU를 사용할 수 없습니다.')\n",
    "\n",
    "check_gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_directory = os.getcwd()\n",
    "os.chdir(current_directory +'/sin')\n",
    "current_directory = os.getcwd()\n",
    "print(\"현재 작업 디렉토리:\", current_directory)\n",
    "\n",
    "image_dir_path = './data_l/' #데이터 최상위 디렉토리\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1, 0.1, 0.1), (0.5, 0.5, 0.5))])\n",
    "\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, image_path, transform=None): \n",
    "        self.image_path = image_path\n",
    "        \n",
    "        self.hazy_path = image_path + '/Hazy'\n",
    "        self.normal_path = image_path + '/Normal'\n",
    "        self.rainy_path = image_path + '/Rainy'\n",
    "        self.snowy_path = image_path + '/Snowy'\n",
    "\n",
    "        self.hazy_img_list = glob.glob(self.hazy_path + '/*.jpg')\n",
    "        self.normal_img_list = glob.glob(self.normal_path + '/*.jpg')\n",
    "        self.rainy_img_list = glob.glob(self.rainy_path + '/*.jpg')\n",
    "        self.snowy_img_list = glob.glob(self.snowy_path + '/*.jpg')\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "        self.img_list = self.hazy_img_list + self.normal_img_list + self.rainy_img_list + self.snowy_img_list\n",
    "        self.class_list = [0] * len(self.hazy_img_list) + [1] * len(self.normal_img_list) + [2] * len(self.rainy_img_list) + [3] * len(self.snowy_img_list) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "        img_path = self.img_list[idx]\n",
    "        label = self.class_list[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "dataset = WeatherDataset(image_path=image_dir_path, transform=transform)\n",
    "print(len(dataset))\n",
    "\n",
    "#학습, 검증 데이터 스플릿\n",
    "\n",
    "train_ratio = 0.8 \n",
    "val_ratio = 1 - train_ratio \n",
    "\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True, \n",
    "                        drop_last=False) #마지막 꼬다리\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False)\n",
    "\n",
    "dataloader_iterator = iter(train_dataloader)\n",
    "first_batch = next(dataloader_iterator)\n",
    "\n",
    "# first_batch 출력\n",
    "print(first_batch)\n",
    "print(first_batch[0].shape) # B, C, W, H 제대로 나오는 거 확인 완료!\n",
    "# 샘플 하나 출력\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "print(type(img)) # <class 'torch.Tensor'> 토치의 이미지 텐서\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0).numpy())  # 채널의 순서를 변경 (C, H, W) -> (H, W, C)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로 바꾼 모델! \n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT 모델 로드\n",
    "class ViTModel(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ViTModel, self).__init__()\n",
    "        self.feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16')\n",
    "        self.vit = ViTForImageClassification.from_pretrained('google/vit-base-patch16')\n",
    "        self.fc = nn.Linear(self.vit.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)['pixel_values']\n",
    "        x = self.vit(x)['logits']\n",
    "        return x\n",
    "\n",
    "num_classes = 4  \n",
    "model = ViTModel(num_classes)\n",
    "# 이미지 전처리 및 예측\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "# 이미지를 모델에 전달하기 전에 전처리 수행\n",
    "image = transform(PIL.Image.open('example.jpg')).unsqueeze(0) \n",
    "outputs = model(image)\n",
    "# 예측 결과 확인\n",
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(\"Predicted class:\", predictions.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 이미지 채널, 크기 설정\n",
    "input_channels = 3\n",
    "input_size = (224, 224)\n",
    "num_classes = len(set(first_batch[1]))\n",
    "#만들어둔 모델 클래스 상속한 객체하나 만들기\n",
    "model = CNNModel(num_classes)\n",
    "#하이퍼파라미터 init\n",
    "learning_rate =  0.0001\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "early_stopping_patience = 10  \n",
    "early_stopping_counter = 0  \n",
    "best_val_loss = float('inf')\n",
    "\n",
    "model_checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(model_checkpoint_dir, exist_ok=True)\n",
    "model_checkpoint_prefix = os.path.join(model_checkpoint_dir, 'model_epoch_')\n",
    "\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch:', epoch + 1)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    model.train()\n",
    "\n",
    "    # tqdm으로 학습 데이터 루프 감싸기\n",
    "    with tqdm(total=len(train_dataloader), unit=\"batch\") as pbar:\n",
    "        for images, labels in train_dataloader:\n",
    "            x, y = images.to(device), labels.long().to(device)  # device에 넣어줌 ; 쿠다 GPU 사용하겠다는 거임!\n",
    "\n",
    "            pred = model(x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "            epoch_correct += pred.argmax(dim=1).eq(y).sum().item()\n",
    "\n",
    "            # tqdm 업데이트\n",
    "            pbar.update(1)\n",
    "\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    model.eval()  # 평가 모드!\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # tqdm을 사용하여 검증 데이터 루프를 감싸기\n",
    "        with tqdm(total=len(val_dataloader), unit=\"batch\") as pbar:\n",
    "            for images, labels in val_dataloader:\n",
    "                x, y = images.to(device), labels.to(device)\n",
    "\n",
    "                pred = model(x)\n",
    "\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                val_loss += loss.item() * len(images)  # 배치 크기 대신 이미지 수로 정규화\n",
    "                val_correct += pred.argmax(dim=1).eq(y).sum().item()\n",
    "\n",
    "                # tqdm 업데이트\n",
    "                pbar.update(1)\n",
    "\n",
    "    print(\"Val Loss:\", val_loss / len(val_dataset))  # 검증 데이터셋 크기로 정규화\n",
    "    print(\"Val Acc:\", (val_correct / len(val_dataset)) * 100)  # 검증 정확도 출력\n",
    "    \n",
    "    \n",
    "    # 얼리스탑핑 체크\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        # 모델 저장\n",
    "        torch.save(model.state_dict(), model_checkpoint_prefix + str(epoch+1) + '.pth')\n",
    "        print(epoch+1, \"번째 model_0920.pth 가 best val_loss 를 경신해서 저장을 완료했다!>.<\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    # 얼리스탑핑 인내 횟수를 초과하면 학습 종료\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# 학습 완료 후 모델 저장\n",
    "torch.save(model.state_dict(), 'model_0920_fin.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트, 평가\n",
    "test_data_dir = 'd:/sin/data_test'\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1, 0.1, 0.1), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_dataset = WeatherDataset(image_path=test_data_dir, transform=test_transform)\n",
    "\n",
    "# 테스트 데이터 공급을 위한 DataLoader 생성\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# 학습한 모델을 로드\n",
    "model.load_state_dict(torch.load('model_0920_fin.pth'))\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "# 오분류된 예측을 저장할 리스트\n",
    "wrong_predictions = []\n",
    "# 예측 및 오분류된 예측 추적\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        x, y = images.to(device), labels.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "        predicted_labels = pred.argmax(dim=1)\n",
    "\n",
    "        # 오분류된 예측을 찾아서 리스트에 저장\n",
    "        wrong_indices = (predicted_labels != y).nonzero().squeeze()\n",
    "        wrong_predictions.extend(wrong_indices.cpu().numpy())\n",
    "\n",
    "# 오분류된 예측 시각화\n",
    "samples = random.sample(wrong_predictions, min(15, len(wrong_predictions)))\n",
    "\n",
    "for n in samples:\n",
    "    print(\"예측확률분포:\", pred[n].cpu().numpy())\n",
    "    print(\"라벨:\", test_dataset.class_list[n], \", 예측결과:\", predicted_labels[n].cpu().numpy())\n",
    "\n",
    "    # 이미지 로드 및 시각화\n",
    "    img = Image.open(test_dataset.img_list[n]).convert('RGB')\n",
    "    img = test_transform(img)\n",
    "    plt.imshow(img.permute(1, 2, 0).numpy())\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
